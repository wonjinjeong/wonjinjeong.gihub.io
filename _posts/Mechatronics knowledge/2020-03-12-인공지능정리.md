---
layout: post
section-type: post
title: 인공지능 정리
category: tech
tags: ['mechatronics', 'AI', 'hunkim', 'pytorch']
published: true
---
Training data set이란

ML이라는 블록이 있다고 가정하고 답이 정해진(label이 정해진) X의 입력과 Y의 출력을 학습한다하면 학습을 한 label이 Training data이고 이 학습을 통해 ML의 모델이 만들어진다. 그러면 이후에 임의로 정한 X값을 넣어주면 ML이 예상된 Y값을 출력해주게 된다.

Supervised Learning의 유형 대개 3가지로 나눌 수 있다.
<div style="text-align:left:">1.Regression</div>
<div style="text-align:left:">2.binary classification</div>
<div style="text-align:left:">3. multi-label classification</div>

Linear Regression이란
우선 Training data는 그래프로 그려보면 선형으로 그려지는데
예를들어 공부를 많이할수록 성적이 오른다.와 같이 많은 가정들을 linear regression으로 표현할 수 있고
수식은 H(x) = Wx +b로 가설을 세울 수 있고 이 수식을 통해 그려진 선중에 무엇이 가장 적합한 선일까?를 알아야한다.
알아낼 수 있는 방법은 실제 데이터와 H(x)와 얼마큼 차이가 있는가에 따라 구별할 수 있다.
H(x) - y로 표현할 수 있다. 하지만 실제로 Cost function(Loss)는 (H(x)-y)^2으로 표현해 차이에 더 무게를 두게 된다.
<img src="/img/mechatronics/cost_function.png" alt="" width="600" height="150">

Linear Regression의 Cost 최소화 알고리즘
cost를 최소화 : 즉 Loss를 최소화해야함 그래야 내가 원하는 실제 값과 같은 값을 얻는 모델을 얻을 수 있기 때문이다.
<img src = "/img/mechatronics/cost_function2.png" alt=""width="600" height="150">
최소화를 위한 Gradient algorithm을 설명하면
비교를 하면서 미분한 값으로 조금씩 값을 찾아가는 방식이다.
<img src = "/img/mechatronics/formal_definition.png" alt=""width="600" height="150">
gradient algorithm을 실제로 미분해보면 다음과 같다.
<img src = "/img/mechatronics/formal_definition2.png" alt=""width="600" height="500">

Multi-variable linear regression일 때
H(x)와 Cost function은 어떻게 될까?
<img src = "/img/mechatronics/multi_regression.png" alt=""width="600" height="350">
Matrix를 이용한 H(x) 표현은
H(X) = XW로 표현할 수 있다.
<img src = "/img/mechatronics/matrix.png" alt = ""width="600" height="350">

위의 입력 변수x와 출력 변수 y에 대해 weight를 곱한 식으로 matrix를 정리하면 다음과 같다.
<img src = "/img/mechatronics/matrix2.png" alt = ""width="600" height="350">

Logistic Classification의 정의
예를들어 시험 pass, fail을 예측하는 시스템이 있다고 했을 때 input의 값이 보편적인 값보다 상당히 차이나는 값으로 training data로 들어오게 된다면 pass, fail의 예측이 불명확해질 수 있다. 이 문제를 해결하기 위해 나온 방법이 sigmoid라는 것인데
<img src = "/img/mechatronics/logistic_hypothesis.png" alt=""width="600" height="150">

Logistic Regression의 cost 함수 정의
H(X)가 위 그림처럼 표현되어 울퉁불퉁한 그래프를 가지게 된다.
<img src = "/img/mechatronics/logistic_hypothesis2.png" alt = ""width="600" height="350">
그래서 위 그림과 같은 문제의 이유로 새로운 cost function의 형태를 만들었는데
<img src = "/img/mechatronics/logistic_cost_function.png" alt = ""width="600" height="200">
cost function은 다음과 같이 다시 정리할 수 있고 이를 다시 gradient방법을 통해 최적화를 하게 된다.
<img src = "/img/mechatronics/logistic_cost_function2.png" alt = ""width="600" height="300">


자료지식은 Youtube에 올라와 있는 Sung Kim님의 자료에서 배울 수 있었습니다.